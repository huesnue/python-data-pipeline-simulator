# Python Data Pipeline Simulator

A modular, object-oriented data pipeline simulator built in Python.  
This project demonstrates how real-world data pipelines are structured internally, including data ingestion, validation, transformation, and pipeline orchestration.  
It is part of my AI/MLOps engineering training and showcases clean architecture, OOP principles, and production-ready code structure.

---

## ğŸš€ Project Overview

Modern machine learning systems rely on robust, maintainable data pipelines.  
This project simulates the core components of such pipelines using Python and object-oriented design.

The goal is to demonstrate:

- Clean and modular software architecture  
- Separation of concerns across pipeline stages  
- Error handling and validation logic  
- Extensibility for future ML/MLOps workflows  

---

## ğŸ§© Features

- **Data Ingestion**  
  Load JSON or CSV files through a dedicated `DataSource` class.

- **Data Validation**  
  Schema checks, type validation, and missing-value detection.

- **Data Transformation**  
  Cleaning, feature extraction, and transformation logic.

- **Pipeline Orchestration**  
  A `PipelineManager` class coordinates all steps with logging and error handling.

- **Extensible Architecture**  
  Easy to add new validators, transformers, or data sources.

---

## ğŸ“ Project Structure

```
python-data-pipeline-simulator/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_source.py
â”‚   â”œâ”€â”€ data_validator.py
â”‚   â”œâ”€â”€ data_transformer.py
â”‚   â”œâ”€â”€ pipeline_manager.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input_sample.json
â”‚   â”œâ”€â”€ input_sample.csv
â”‚   â””â”€â”€ schema.json
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data_source.py
â”‚   â”œâ”€â”€ test_data_validator.py
â”‚   â”œâ”€â”€ test_data_transformer.py
â”‚   â””â”€â”€ test_pipeline_manager.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture_diagram.png
â”‚   â”œâ”€â”€ pipeline_flow.md
â”‚   â””â”€â”€ class_design.md
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

## ğŸ› ï¸ Technologies Used

- Python 3.x  
- OOP design patterns  
- JSON & CSV handling  
- Logging  
- (Optional) Pandas, NumPy  
- (Optional) Pytest for unit tests  

---

## â–¶ï¸ How to Run

1. Clone the repository:

```
git clone `https://github.com/huesnue/python-data-pipeline-simulator.git` [(github.com in Bing)](https://www.bing.com/search?q="https%3A%2F%2Fgithub.com%2Fhuesnue%2Fpython-data-pipeline-simulator.git")
cd python-data-pipeline-simulator
```

2. Install dependencies:

```
pip install -r requirements.txt
```

3. Run the pipeline:

```python
from src.pipeline_manager import PipelineManager
from src.data_source import DataSource
from src.data_validator import DataValidator
from src.data_transformer import DataTransformer

pipeline = PipelineManager(
    source=DataSource("data/input_sample.json"),
    validator=DataValidator("data/schema.json"),
    transformer=DataTransformer()
)

pipeline.run()
```

---

## ğŸ“ Architecture

The pipeline follows a clean, modular architecture:

```
DataSource â†’ DataValidator â†’ DataTransformer â†’ PipelineManager
```

Each component is isolated and testable.

---

## ğŸ“š What I Learned

- Designing maintainable Python modules  
- Applying OOP principles to real-world data workflows  
- Implementing schema validation and transformation logic  
- Structuring ML/MLOpsâ€‘ready pipelines  
- Writing clean, extensible, productionâ€‘style code  

---

## ğŸ”® Future Extensions

- Add CLI interface  
- Add database connectors (SQL, NoSQL)  
- Add parallel processing  
- Add unit tests for all components  
- Add integration with cloud storage (S3, GCS, Azure Blob)  

---

## ğŸ“„ License

MIT License

